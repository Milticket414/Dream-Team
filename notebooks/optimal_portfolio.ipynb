{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the optimal portfolio. The code works and runs well, but we need to use a clean dataframe for this to work CORRECTLY.\n",
    "\n",
    "# In this code, as of now, we used \"working\" as our dataframe... however, we noticed that the bitcoin information was flawed. In order to put this on dashboard, we need to clean up the dataframe.\n",
    "\n",
    "# you can find the dataframe \"working\" or any other of its kind on Jorge's .ipynb\n",
    "\n",
    "# dataframes have been pushed to a csv (fang_sum for the total price of all fang stocks daily in the clean data directory) (\"working\" is a csv in the raw_csv directory named \"daily_prices_all_ugly\")\n",
    "\n",
    "# the goal is to match the Bitcoin prices to the Fang Sum in a way that makes since (ie Bitcoin should be around 12 or 13k instead of 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_project = [\"Gold\", \"sp500\", \"VNQ\", \"BITCOIN\", \"FAANG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Portfolio\"\n",
    "# created using the daily prices of all assets above\n",
    "working = working \n",
    "#Create and plot the graph\n",
    "plt.figure(figsize=(12.2,4.5)) #width = 12.2in, height = 4.5\n",
    "# Loop through each stock and plot the Adj Close for each day\n",
    "for c in working.columns.values:\n",
    "  plt.plot( working[c],  label=c)#plt.plot( X-Axis , Y-Axis, line_width, alpha_for_blending,  label)\n",
    "plt.title(title)\n",
    "plt.xlabel('Date',fontsize=18)\n",
    "plt.ylabel('Percent Change ($)',fontsize=18)\n",
    "plt.legend(working.columns.values, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = working.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix_annual = working.cov() * 252\n",
    "cov_matrix_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Portfolio Vaariance\n",
    "port_variance = np.dot(weights.T, np.dot(cov_matrix_annual, weights))\n",
    "port_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volatility(Standard Deviation)\n",
    "port_volatility = np.sqrt(port_variance)\n",
    "port_volatility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annual Return\n",
    "portfolioSimpleAnnualReturn = np.sum(working.mean()*weights) * 252\n",
    "portfolioSimpleAnnualReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_var = str(round(port_variance, 2) * 100) + '%'\n",
    "percent_vols = str(round(port_volatility, 2) * 100) + '%'\n",
    "percent_ret = str(round(portfolioSimpleAnnualReturn, 2)*100)+'%'\n",
    "print(\"Expected annual return : \"+ percent_ret)\n",
    "print('Annual volatility/standard deviation/risk : '+percent_vols)\n",
    "print('Annual variance : '+percent_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = expected_returns.mean_historical_return(working)\n",
    "S = risk_models.sample_cov(working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef = EfficientFrontier(mu, S)\n",
    "weights = ef.max_sharpe() #Maximize the Sharpe ratio, and get the raw weights\n",
    "cleaned_weights = ef.clean_weights() \n",
    "print(cleaned_weights) #Note the weights may have some rounding error, meaning they may not add up exactly to 1 but should be close\n",
    "ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
    "latest_prices = get_latest_prices(working)\n",
    "weights = cleaned_weights \n",
    "da = DiscreteAllocation(weights, latest_prices, total_portfolio_value=150000)\n",
    "allocation, leftover = da.lp_portfolio()\n",
    "print(\"Discrete allocation:\", allocation)\n",
    "print(\"Funds remaining: ${:.2f}\".format(leftover))"
   ]
  }
 ]
}